{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Harshit Aggarwal | 2021111015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "701 3038\n",
      "801 1677\n",
      "1416 2278\n",
      "1416 2594\n",
      "1653 2598\n",
      "1663 2122\n",
      "1778 2485\n",
      "1780 2320\n",
      "2616 1731\n",
      "2482 3481\n"
     ]
    }
   ],
   "source": [
    "image_path = 'calib-object.jpg'\n",
    "image = cv2.imread(image_path)\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "corners = cv2.goodFeaturesToTrack(gray_image, maxCorners=300, qualityLevel=0.4, minDistance=10)\n",
    "if corners is not None:\n",
    "    corners = (np.intp(corners).reshape(np.intp(corners).shape[0], 2))\n",
    "    sorted_indices = np.argsort(corners[:, 0])\n",
    "    corners = corners[sorted_indices]\n",
    "    # 18 19 28 34 39 41\n",
    "    required_corners = np.array([1, 2, 18, 19, 28, 34, 39, 41, 89, 82])\n",
    "    for corner in corners[required_corners]:\n",
    "        x, y = corner.ravel()\n",
    "        print(x, y)\n",
    "        cv2.circle(image, (x, y), 20, (255, 0, 0), -1)\n",
    "    required_world_coordinates = np.array([[0, -2, 12], [0, 12, 10], [0, 4, 2], [0, 0, 2], [2, 0, 0], [2, 6, 0], [4, 2, 0], [4, 4, 0], [14, 12, 0], [14, -6, 0]])\n",
    "    required_image_coordinates = corners[required_corners]\n",
    "    desired_width = 800\n",
    "    desired_height = 600\n",
    "    height, width, channels = image.shape\n",
    "    ratio_width = desired_width / width\n",
    "    ratio_height = desired_height / height\n",
    "    ratio = min(ratio_width, ratio_height)\n",
    "    new_width = int(width * ratio)\n",
    "    new_height = int(height * ratio)\n",
    "    resized_img = cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_AREA)\n",
    "    cv2.imshow('Chessboard', resized_img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print(\"No corners were found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_homography(image_points, world_points):\n",
    "    A = []\n",
    "    for i in range(len(image_points)):\n",
    "        X, Y, Z = world_points[i]\n",
    "        x, y = image_points[i]\n",
    "        A.append([X, Y, Z, 1, 0, 0, 0, 0, -x*X, -x*Y, -x*Z, -x])\n",
    "        A.append([0, 0, 0, 0, X, Y, Z, 1, -y*X, -y*Y, -y*Z, -y])\n",
    "    A = np.array(A)\n",
    "    A *= -1\n",
    "    \n",
    "    _, s, vh = np.linalg.svd(A)\n",
    "    m = vh[np.argmin(s), :]\n",
    "    M = m.reshape(3, 4)\n",
    "    # print(M)\n",
    "\n",
    "    MMT = M[:, :3] @ M[:, :3].T\n",
    "    mm11, mm21, mm13, mm22, mm23 = MMT[0, 0], MMT[1, 0], MMT[0, 2], MMT[1, 1], MMT[1, 2]\n",
    "    u0 = mm13\n",
    "    v0 = mm23\n",
    "    beta = np.sqrt(mm22 - v0**2)\n",
    "    gamma = (mm21 - u0*v0) / beta\n",
    "    alpha = np.sqrt(mm11 - gamma**2 - u0**2)\n",
    "    K = np.array([[alpha, gamma, u0],\n",
    "                [0,     beta,  v0],\n",
    "                [0,     0,     1]])\n",
    "    R = np.linalg.inv(K) @ M[:, :3]\n",
    "    t = np.linalg.inv(K) @ M[:, 3]\n",
    "    return K, R, t, M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intrinsic Matrix:\n",
      " [[2.87593171e-02 5.51746604e-03 8.45478197e-08]\n",
      " [0.00000000e+00 3.08689236e-02 1.10790208e-07]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n",
      "Rotation Matrix:\n",
      " [[-4.04701924e-01 -9.01853873e-02  9.09990631e-01]\n",
      " [ 1.83278637e-01  9.66933276e-01  1.77338605e-01]\n",
      " [ 5.12849870e-06  1.83432101e-06  4.93656128e-06]]\n",
      "Translation Vector:\n",
      " [-1.26246540e+01 -2.77150907e+01 -3.35281612e-04]\n",
      "projection Matrix:\n",
      " [[-1.06277173e-02  2.74135137e-03  2.71491688e-02 -5.15993498e-01]\n",
      " [ 5.65761426e-03  2.98481895e-02  5.47425186e-03 -8.55535018e-01]\n",
      " [ 5.12849870e-06  1.83432101e-06  4.93656128e-06 -3.35281612e-04]]\n",
      "1417.0718594646435 2279.972987237213\n"
     ]
    }
   ],
   "source": [
    "K, R, t, P = compute_homography(required_image_coordinates, required_world_coordinates)\n",
    "print(\"Intrinsic Matrix:\\n\", K)\n",
    "print(\"Rotation Matrix:\\n\", R)\n",
    "print(\"Translation Vector:\\n\", t)\n",
    "print(\"projection Matrix:\\n\", P)\n",
    "hh = P @ np.array([0, 4, 2, 1])\n",
    "print(hh[0]/hh[2], hh[1]/hh[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "wireframe_points_world = np.array([\n",
    "    [14, 12, 0],\n",
    "    [0, 12, 0],\n",
    "    [14, -6, 0],\n",
    "    [0, -6, 0]\n",
    "], dtype=float)\n",
    "wireframe_points_world_homogeneous = np.hstack((wireframe_points_world, np.ones((4, 1))))\n",
    "wireframe_points_image_homogeneous = np.dot(P, wireframe_points_world_homogeneous.T).T\n",
    "wireframe_points_image = (wireframe_points_image_homogeneous / wireframe_points_image_homogeneous[:, -1].reshape(-1, 1))[:, :2]\n",
    "for start, end in zip([0, 0, 1, 3], [1, 2, 3, 2]):\n",
    "    cv2.line(image, tuple(wireframe_points_image[start].astype(int)), tuple(wireframe_points_image[end].astype(int)), (0, 255, 0), 3)\n",
    "wireframe_points_world = np.array([\n",
    "    [0, 12, 14],\n",
    "    [0, 12, 0],\n",
    "    [0, -6, 14],\n",
    "    [0, -6, 0]\n",
    "], dtype=float)\n",
    "wireframe_points_world_homogeneous = np.hstack((wireframe_points_world, np.ones((4, 1))))\n",
    "wireframe_points_image_homogeneous = np.dot(P, wireframe_points_world_homogeneous.T).T\n",
    "wireframe_points_image = (wireframe_points_image_homogeneous / wireframe_points_image_homogeneous[:, -1].reshape(-1, 1))[:, :2]\n",
    "for start, end in zip([0, 0, 1, 3], [1, 2, 3, 2]):\n",
    "    cv2.line(image, tuple(wireframe_points_image[start].astype(int)), tuple(wireframe_points_image[end].astype(int)), (0, 255, 0), 3)\n",
    "desired_width = 800\n",
    "desired_height = 600\n",
    "height, width, channels = image.shape\n",
    "ratio_width = desired_width / width\n",
    "ratio_height = desired_height / height\n",
    "ratio = min(ratio_width, ratio_height)\n",
    "new_width = int(width * ratio)\n",
    "new_height = int(height * ratio)\n",
    "resized_img = cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_AREA)\n",
    "cv2.imshow('Chessboard', resized_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pitch (Tilt): -0.00 degrees\n",
      "Roll: 20.38 degrees\n",
      "Yaw (Pan): 155.64 degrees\n"
     ]
    }
   ],
   "source": [
    "pitch = np.arcsin(-R[2, 0])\n",
    "roll = np.arctan2(R[2, 1], R[2, 2])\n",
    "yaw = np.arctan2(R[1, 0], R[0, 0])\n",
    "pitch_deg = np.degrees(pitch)\n",
    "roll_deg = np.degrees(roll)\n",
    "yaw_deg = np.degrees(yaw)\n",
    "print(f\"Pitch (Tilt): {pitch_deg:.2f} degrees\")\n",
    "print(f\"Roll: {roll_deg:.2f} degrees\")\n",
    "print(f\"Yaw (Pan): {yaw_deg:.2f} degrees\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explaination:\n",
    "These values will change according to the world coordinates choosen. These represent the tilt, roll and pan of the camera in the world frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "701 3038\n",
      "801 1677\n",
      "1416 2278\n",
      "1416 2594\n",
      "1653 2598\n",
      "1663 2122\n",
      "1778 2485\n",
      "1780 2320\n",
      "1777 2650\n",
      "1790 1984\n",
      "1791 1807\n",
      "2616 1731\n",
      "2482 3481\n"
     ]
    }
   ],
   "source": [
    "image_path = 'calib-object.jpg'\n",
    "image = cv2.imread(image_path)\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "corners = cv2.goodFeaturesToTrack(gray_image, maxCorners=300, qualityLevel=0.4, minDistance=10)\n",
    "if corners is not None:\n",
    "    corners = (np.intp(corners).reshape(np.intp(corners).shape[0], 2))\n",
    "    sorted_indices = np.argsort(corners[:, 0])\n",
    "    corners = corners[sorted_indices]\n",
    "    # 18 19 28 34 39 41 38 43\n",
    "    required_corners = np.array([1, 2, 18, 19, 28, 34, 39, 41, 38, 43, 44, 89, 82])\n",
    "    for corner in corners[required_corners]:\n",
    "        x, y = corner.ravel()\n",
    "        print(x, y)\n",
    "        cv2.circle(image, (x, y), 20, (255, 0, 0), -1)\n",
    "    required_world_coordinates = np.array([[0, -2, 12], [0, 12, 10], [0, 4, 2], [0, 0, 2], [2, 0, 0], [2, 6, 0], [4, 2, 0], [4, 4, 0], [4, 0, 0], [4, 8, 0], [4, 10, 0], [14, 12, 0], [14, -6, 0]])\n",
    "    required_image_coordinates = corners[required_corners]\n",
    "    desired_width = 800\n",
    "    desired_height = 600\n",
    "    height, width, channels = image.shape\n",
    "    ratio_width = desired_width / width\n",
    "    ratio_height = desired_height / height\n",
    "    ratio = min(ratio_width, ratio_height)\n",
    "    new_width = int(width * ratio)\n",
    "    new_height = int(height * ratio)\n",
    "    resized_img = cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_AREA)\n",
    "    cv2.imshow('Chessboard', resized_img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print(\"No corners were found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.63677643e+03 0.00000000e+00 1.47706423e+03]\n",
      " [0.00000000e+00 3.62025059e+03 2.13304171e+03]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]] [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]] [[ 1.43251747e+03 -4.01715560e+02 -3.63240689e+03  6.98520146e+04]\n",
      " [-8.16727077e+02 -4.05461157e+03 -7.41055432e+02  1.15818149e+05]\n",
      " [-7.06938114e-01 -2.63733743e-01 -6.56264441e-01  4.53800311e+01]]\n",
      "1417.7330607705924 2281.1377715777144\n"
     ]
    }
   ],
   "source": [
    "object_points_plane1 = required_world_coordinates[4:]\n",
    "image_points_plane1 = required_image_coordinates[4:]\n",
    "object_points_plane1_ = [object_points_plane1.reshape(-1, 1, 3).astype(np.float32)]\n",
    "image_points_plane1_ = [image_points_plane1.reshape(-1, 1, 2).astype(np.float32)]\n",
    "# print(object_points_plane1_)\n",
    "# print(image_points_plane1_)\n",
    "dist_coeffs = np.zeros((5, 1), dtype=np.float32)\n",
    "camera_matrix = np.array([\n",
    "    [gray_image.shape[::-1][0], 0, gray_image.shape[::-1][0]/2],\n",
    "    [0, gray_image.shape[::-1][1], gray_image.shape[::-1][1]/2],\n",
    "    [0, 0, 1]\n",
    "], dtype=np.float32)\n",
    "ret, camera_matrix, _, rvecs, tvecs = cv2.calibrateCamera(\n",
    "    object_points_plane1_,\n",
    "    image_points_plane1_,\n",
    "    gray_image.shape[::-1],\n",
    "    camera_matrix,\n",
    "    dist_coeffs,\n",
    "    flags=cv2.CALIB_USE_INTRINSIC_GUESS | cv2.CALIB_FIX_K1 | cv2.CALIB_FIX_K2 | \n",
    "          cv2.CALIB_FIX_K3 | cv2.CALIB_FIX_K4 | cv2.CALIB_FIX_K5 | cv2.CALIB_FIX_K6\n",
    ")\n",
    "object_points_plane2 = required_world_coordinates[:4]\n",
    "image_points_plane2 = required_image_coordinates[:4]\n",
    "all_object_points = np.concatenate((object_points_plane1, object_points_plane2), axis=0)\n",
    "all_image_points = np.concatenate((image_points_plane1, image_points_plane2), axis=0)\n",
    "all_object_points_ = [all_object_points.reshape(-1, 1, 3).astype(np.float32)]\n",
    "all_image_points_ = [all_image_points.reshape(-1, 1, 2).astype(np.float32)]\n",
    "# print(all_object_points_)\n",
    "# print(all_image_points_)\n",
    "ret, camera_matrix, _, rvecs, tvecs = cv2.calibrateCamera(\n",
    "    all_object_points_,\n",
    "    all_image_points_,\n",
    "    gray_image.shape[::-1],\n",
    "    camera_matrix,\n",
    "    dist_coeffs,\n",
    "    flags=cv2.CALIB_USE_INTRINSIC_GUESS | cv2.CALIB_FIX_K1 | cv2.CALIB_FIX_K2 | \n",
    "          cv2.CALIB_FIX_K3 | cv2.CALIB_FIX_K4 | cv2.CALIB_FIX_K5 | cv2.CALIB_FIX_K6\n",
    ")\n",
    "projection_matrix = []\n",
    "for rvec, tvec in zip(rvecs, tvecs):\n",
    "        R, _ = cv2.Rodrigues(rvec)\n",
    "        extrinsic_matrix = np.hstack((R, tvec))\n",
    "        projection_matrix = np.dot(camera_matrix, extrinsic_matrix)\n",
    "print(camera_matrix, dist_coeffs, projection_matrix)\n",
    "hh = projection_matrix @ np.array([0, 4, 2, 1])\n",
    "print(hh[0]/hh[2], hh[1]/hh[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = projection_matrix\n",
    "\n",
    "wireframe_points_world = np.array([\n",
    "    [14, 12, 0],\n",
    "    [0, 12, 0],\n",
    "    [14, -6, 0],\n",
    "    [0, -6, 0]\n",
    "], dtype=float)\n",
    "wireframe_points_world_homogeneous = np.hstack((wireframe_points_world, np.ones((4, 1))))\n",
    "wireframe_points_image_homogeneous = np.dot(P, wireframe_points_world_homogeneous.T).T\n",
    "wireframe_points_image = (wireframe_points_image_homogeneous / wireframe_points_image_homogeneous[:, -1].reshape(-1, 1))[:, :2]\n",
    "for start, end in zip([0, 0, 1, 3], [1, 2, 3, 2]):\n",
    "    cv2.line(image, tuple(wireframe_points_image[start].astype(int)), tuple(wireframe_points_image[end].astype(int)), (0, 255, 0), 3)\n",
    "wireframe_points_world = np.array([\n",
    "    [0, 12, 14],\n",
    "    [0, 12, 0],\n",
    "    [0, -6, 14],\n",
    "    [0, -6, 0]\n",
    "], dtype=float)\n",
    "wireframe_points_world_homogeneous = np.hstack((wireframe_points_world, np.ones((4, 1))))\n",
    "wireframe_points_image_homogeneous = np.dot(P, wireframe_points_world_homogeneous.T).T\n",
    "wireframe_points_image = (wireframe_points_image_homogeneous / wireframe_points_image_homogeneous[:, -1].reshape(-1, 1))[:, :2]\n",
    "for start, end in zip([0, 0, 1, 3], [1, 2, 3, 2]):\n",
    "    cv2.line(image, tuple(wireframe_points_image[start].astype(int)), tuple(wireframe_points_image[end].astype(int)), (0, 255, 0), 3)\n",
    "desired_width = 800\n",
    "desired_height = 600\n",
    "height, width, channels = image.shape\n",
    "ratio_width = desired_width / width\n",
    "ratio_height = desired_height / height\n",
    "ratio = min(ratio_width, ratio_height)\n",
    "new_width = int(width * ratio)\n",
    "new_height = int(height * ratio)\n",
    "resized_img = cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_AREA)\n",
    "cv2.imshow('Chessboard', resized_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explaination:\n",
    "We had to calibrate twice in the case of the inbuilt function beacause it basically calibrates for objects in the sam plane. The calibration for both the inbuilt function and the self inplimented function are a bit distorted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera matrix:\n",
      " [[3.18376820e+03 0.00000000e+00 1.06286689e+03]\n",
      " [0.00000000e+00 2.28507983e+03 1.02256268e+03]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n",
      "Distortion coefficients:\n",
      " [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Rotation Vectors:\n",
      " (array([[-1.00917651],\n",
      "       [-0.01888391],\n",
      "       [ 0.00621452]]),)\n",
      "Translation Vectors:\n",
      " (array([[-3.97906086],\n",
      "       [-5.6893279 ],\n",
      "       [65.061719  ]]),)\n",
      "Projection Matrix:\n",
      " [array([[ 3.19696368e+03, -8.88343113e+02,  5.06296037e+02,\n",
      "         5.64835392e+04],\n",
      "       [ 4.51465780e+01,  3.51448331e+02,  2.47823932e+03,\n",
      "         5.35291173e+04],\n",
      "       [ 1.29583475e-02, -8.46387493e-01,  5.32409892e-01,\n",
      "         6.50617190e+01]])]\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('assign1.jpg')\n",
    "number_of_squares_X = 5\n",
    "number_of_squares_Y = 5\n",
    "square_size = 2.0\n",
    "\n",
    "object_points = np.zeros((number_of_squares_X * number_of_squares_Y, 3), np.float32)\n",
    "object_points[:, :2] = np.mgrid[0:number_of_squares_X, 0:number_of_squares_Y].T.reshape(-1, 2)\n",
    "object_points = object_points * square_size\n",
    "\n",
    "object_points_array = []\n",
    "image_points_array = []\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "ret, corners = cv2.findChessboardCorners(gray, (number_of_squares_X, number_of_squares_Y), None)\n",
    "if ret:\n",
    "    object_points_array.append(object_points)\n",
    "    corners_corrected = cv2.cornerSubPix(gray, corners, (11, 11), (-1, -1), (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001))\n",
    "    image_points_array.append(corners_corrected)\n",
    "\n",
    "    img = cv2.drawChessboardCorners(img, (number_of_squares_X, number_of_squares_Y), corners_corrected, ret)\n",
    "\n",
    "    desired_width = 800\n",
    "    desired_height = 600\n",
    "    height, width, channels = img.shape\n",
    "    ratio_width = desired_width / width\n",
    "    ratio_height = desired_height / height\n",
    "    ratio = min(ratio_width, ratio_height)\n",
    "    new_width = int(width * ratio)\n",
    "    new_height = int(height * ratio)\n",
    "    resized_img = cv2.resize(img, (new_width, new_height), interpolation=cv2.INTER_AREA)\n",
    "    cv2.imshow('Chessboard', resized_img)\n",
    "    cv2.waitKey(0)\n",
    "else:\n",
    "    print(\"fuck\")\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "if len(object_points_array) > 0:\n",
    "    camera_matrix = np.array([[gray.shape[1], 0, gray.shape[1]/2],\n",
    "                          [0, gray.shape[0], gray.shape[0]/2],\n",
    "                          [0, 0, 1]], dtype=float)\n",
    "    dist_coeffs = np.zeros((5, 1))\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(object_points_array, image_points_array, gray.shape[::-1], camera_matrix, dist_coeffs, flags=cv2.CALIB_USE_INTRINSIC_GUESS + cv2.CALIB_ZERO_TANGENT_DIST + cv2.CALIB_FIX_K1 + cv2.CALIB_FIX_K2 + cv2.CALIB_FIX_K3 + cv2.CALIB_FIX_K4 + cv2.CALIB_FIX_K5 + cv2.CALIB_FIX_K6)\n",
    "    projection_matrices = []\n",
    "    for rvec, tvec in zip(rvecs, tvecs):\n",
    "        R, _ = cv2.Rodrigues(rvec)\n",
    "        extrinsic_matrix = np.hstack((R, tvec))\n",
    "        projection_matrix = np.dot(mtx, extrinsic_matrix)\n",
    "        projection_matrices.append(projection_matrix)\n",
    "    print(\"Camera matrix:\\n\", mtx)\n",
    "    print(\"Distortion coefficients:\\n\", dist)\n",
    "    print(\"Rotation Vectors:\\n\", rvecs)\n",
    "    print(\"Translation Vectors:\\n\", tvecs)\n",
    "    print(\"Projection Matrix:\\n\", projection_matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "R, _ = cv2.Rodrigues(rvecs[0])\n",
    "t = tvecs[0]\n",
    "P = np.matmul(mtx, np.hstack((R, t)))\n",
    "wireframe_points_world = np.array([\n",
    "    [0, 0, 0],\n",
    "    [0, (number_of_squares_Y - 1) * square_size, 0],\n",
    "    [(number_of_squares_X - 1) * square_size, 0, 0],\n",
    "    [(number_of_squares_X - 1) * square_size, (number_of_squares_Y - 1) * square_size, 0],\n",
    "], dtype=float)\n",
    "wireframe_points_world_homogeneous = np.hstack((wireframe_points_world, np.ones((4, 1))))\n",
    "wireframe_points_image_homogeneous = np.dot(P, wireframe_points_world_homogeneous.T).T\n",
    "wireframe_points_image = (wireframe_points_image_homogeneous / wireframe_points_image_homogeneous[:, -1].reshape(-1, 1))[:, :2]\n",
    "patch_coordinates = wireframe_points_image\n",
    "for start, end in zip([0, 0, 1, 3], [1, 2, 3, 2]):\n",
    "    cv2.line(img, tuple(wireframe_points_image[start].astype(int)), tuple(wireframe_points_image[end].astype(int)), (0, 255, 0), 3)\n",
    "desired_width = 800\n",
    "desired_height = 600\n",
    "height, width, channels = img.shape\n",
    "ratio_width = desired_width / width\n",
    "ratio_height = desired_height / height\n",
    "ratio = min(ratio_width, ratio_height)\n",
    "new_width = int(width * ratio)\n",
    "new_height = int(height * ratio)\n",
    "resized_img = cv2.resize(img, (new_width, new_height), interpolation=cv2.INTER_AREA)\n",
    "cv2.imshow('Wireframe Overlay', resized_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explaination:\n",
    "The calibration seems to be perfect in this case bacause I used the all the chessboard coordinates for calibration. But ideally, the calibration in case of objects in one plane can be a bit distorted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "868.1531944135427 822.743667274874\n"
     ]
    }
   ],
   "source": [
    "print((P @ [0, 0, 0, 1])[0]/(P @ [0, 0, 0, 1])[2], (P @ [0, 0, 0, 1])[1]/(P @ [0, 0, 0, 1])[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explaination:\n",
    "Yes this result aggrees with my observation. Since, the world coordinate i choose was corresponding to these pixel values only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "R, _ = cv2.Rodrigues(rvecs[0])\n",
    "t = tvecs[0]\n",
    "P = np.matmul(mtx, np.hstack((R, t)))\n",
    "wireframe_points_world = np.array([\n",
    "    [0+10, 0, 0],\n",
    "    [0+10, (number_of_squares_Y - 1) * square_size, 0],\n",
    "    [(number_of_squares_X - 1) * square_size+10, 0, 0],\n",
    "    [(number_of_squares_X - 1) * square_size+10, (number_of_squares_Y - 1) * square_size, 0],\n",
    "], dtype=float)\n",
    "wireframe_points_world_homogeneous = np.hstack((wireframe_points_world, np.ones((4, 1))))\n",
    "wireframe_points_image_homogeneous = np.dot(P, wireframe_points_world_homogeneous.T).T\n",
    "wireframe_points_image = (wireframe_points_image_homogeneous / wireframe_points_image_homogeneous[:, -1].reshape(-1, 1))[:, :2]\n",
    "for start, end in zip([0, 0, 1, 3], [1, 2, 3, 2]):\n",
    "    cv2.line(img, tuple(wireframe_points_image[start].astype(int)), tuple(wireframe_points_image[end].astype(int)), (0, 255, 0), 3)\n",
    "desired_width = 800\n",
    "desired_height = 600\n",
    "height, width, channels = img.shape\n",
    "ratio_width = desired_width / width\n",
    "ratio_height = desired_height / height\n",
    "ratio = min(ratio_width, ratio_height)\n",
    "new_width = int(width * ratio)\n",
    "new_height = int(height * ratio)\n",
    "resized_img = cv2.resize(img, (new_width, new_height), interpolation=cv2.INTER_AREA)\n",
    "cv2.imshow('Wireframe Overlay', resized_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explaination:\n",
    "Yes the frame looks consistant. Its a bit skewed as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_point_in_poly(x, y, poly):\n",
    "    num = len(poly)\n",
    "    j = num - 1\n",
    "    c = False\n",
    "    for i in range(num):\n",
    "        if ((poly[i][1] > y) != (poly[j][1] > y)) and (x < poly[i][0] + (poly[j][0] - poly[i][0]) * (y - poly[i][1]) / (poly[j][1] - poly[i][1])):\n",
    "            c = not c\n",
    "        j = i\n",
    "    return c\n",
    "\n",
    "def iterate_polygon_points(polygon):\n",
    "    minX = min(polygon, key=lambda p: p[0])[0]\n",
    "    maxX = max(polygon, key=lambda p: p[0])[0]\n",
    "    minY = min(polygon, key=lambda p: p[1])[1]\n",
    "    maxY = max(polygon, key=lambda p: p[1])[1]\n",
    "    output = []\n",
    "    for x in range(minX, maxX + 1):\n",
    "        for y in range(minY, maxY + 1):\n",
    "            if is_point_in_poly(x, y, polygon):\n",
    "                output.append([x, y])\n",
    "    return output\n",
    "polygon = patch_coordinates.astype(int)\n",
    "temp = polygon[1].copy()\n",
    "polygon[1] = polygon[2].copy()\n",
    "polygon[2] = polygon[3].copy()\n",
    "polygon[3] = temp.copy()\n",
    "patch_pixel_coordinates = iterate_polygon_points(polygon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagee = cv2.imread(\"assign1.jpg\")\n",
    "image = imagee.copy()\n",
    "R_copy = R.copy()\n",
    "R_copy[:, 2] = np.array([t[0][0], t[1][0], t[2][0]])\n",
    "K_inv = np.linalg.inv(mtx)\n",
    "R_inv = np.linalg.inv(R_copy)\n",
    "P_inv = R_inv @ K_inv\n",
    "for u, v in patch_pixel_coordinates:\n",
    "        world_coordinates = P_inv @ np.array([u, v, 1])\n",
    "        world_coordinates = [world_coordinates[0]/world_coordinates[2], world_coordinates[1]/world_coordinates[2], 0]\n",
    "        new_world_coordinates = world_coordinates\n",
    "        new_world_coordinates[0] += 10\n",
    "        new_world_coordinates.append(1)\n",
    "        point_image_homogeneous = np.dot(P, new_world_coordinates)\n",
    "        point_image_new = point_image_homogeneous[:2] / point_image_homogeneous[2]\n",
    "        image[int(point_image_new[1]), int(point_image_new[0])] = image[int(v), int(u)].copy()\n",
    "desired_width = 800\n",
    "desired_height = 600\n",
    "height, width, channels = image.shape\n",
    "ratio_width = desired_width / width\n",
    "ratio_height = desired_height / height\n",
    "ratio = min(ratio_width, ratio_height)\n",
    "new_width = int(width * ratio)\n",
    "new_height = int(height * ratio)\n",
    "resized_image = cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_AREA)\n",
    "cv2.imshow('Wireframe Overlay', resized_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explaination:\n",
    "Yes the overlay seems to be perfect and fit the original wireframe completely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
